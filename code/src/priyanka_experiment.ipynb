{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTfZunNburS1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "</b>Step 1: Data Collection & Preprocessing </b>\n",
        "\n",
        "We assume customer data in a CSV format."
      ],
      "metadata": {
        "id": "ZLCYNq37uxMx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I5TXREsBuzYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Sentiment Analysis\n",
        "\n",
        "\n",
        "Using VADER & BERT for social media sentiment analysis."
      ],
      "metadata": {
        "id": "-mBFevTOvCnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Install Required Libraries\n",
        "\n",
        "!pip install pandas numpy scikit-learn transformers vaderSentiment"
      ],
      "metadata": {
        "id": "IRseAfZvvDz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load Data\n",
        "df = pd.read_csv(\"customer_data.csv\")\n",
        "\n",
        "# Initialize Sentiment Analyzers\n",
        "vader = SentimentIntensityAnalyzer()\n",
        "bert_sentiment = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "# Function to analyze sentiment\n",
        "def analyze_sentiment(text):\n",
        "    if pd.isna(text):\n",
        "        return 0  # Neutral if no text\n",
        "    vader_score = vader.polarity_scores(text)['compound']\n",
        "    bert_score = bert_sentiment(text)[0]['score']\n",
        "    return (vader_score + bert_score) / 2  # Averaging sentiment scores\n",
        "\n",
        "df['Sentiment Score'] = df['Social Media Activity'].apply(analyze_sentiment)\n",
        "df.to_csv(\"processed_data.csv\", index=False)\n",
        "print(\"Sentiment Analysis Complete âœ…\")"
      ],
      "metadata": {
        "id": "sXBHKD2kvQRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SQiYBFzHvXHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Building the Recommendation System\n",
        "\n",
        "Using a Hybrid Model:\n",
        "\n",
        "Collaborative Filtering (ALS Model)\n",
        "\n",
        "Content-Based Filtering (TF-IDF + BERT embeddings)\n",
        "\n",
        "Generative AI for explanations"
      ],
      "metadata": {
        "id": "Hn9KZbnQvx-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install surprise"
      ],
      "metadata": {
        "id": "rDBD8P53vy94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Collaborative Filtering with ALS\n",
        "\n"
      ],
      "metadata": {
        "id": "OSPqtia9v4Ll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import Dataset, Reader\n",
        "from surprise import SVD\n",
        "from surprise.model_selection import train_test_split\n",
        "\n",
        "# Load Data\n",
        "data = pd.read_csv(\"processed_data.csv\")\n",
        "\n",
        "# Convert Data for Surprise Library\n",
        "reader = Reader(rating_scale=(0, 1))\n",
        "customer_data = Dataset.load_from_df(data[['User ID', 'Purchase History', 'Sentiment Score']], reader)\n",
        "\n",
        "# Split Data\n",
        "trainset, testset = train_test_split(customer_data, test_size=0.2)\n",
        "\n",
        "# Train ALS Model\n",
        "model = SVD()\n",
        "model.fit(trainset)\n",
        "\n",
        "# Generate Recommendations\n",
        "def recommend(user_id):\n",
        "    products = data['Purchase History'].unique()\n",
        "    predictions = [model.predict(user_id, product) for product in products]\n",
        "    recommendations = sorted(predictions, key=lambda x: x.est, reverse=True)[:5]\n",
        "    return [rec.iid for rec in recommendations]\n",
        "\n",
        "print(\"Top 5 Recommendations for User 101:\", recommend(101))"
      ],
      "metadata": {
        "id": "zl7-BFrKv9GH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yWhDfLW5wCxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Generative AI for\n",
        "Hyper-Personalization\n",
        "We use GPT-4 to generate personalized product descriptions.\n",
        "\n",
        "Code for AI-Powered Personalization"
      ],
      "metadata": {
        "id": "R0b_1UScwG4w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YQgVfmInwFxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "openai.api_key = \"your_api_key_here\"\n",
        "\n",
        "def generate_personalized_message(user_id):\n",
        "    user_data = data[data[\"User ID\"] == user_id].iloc[0]\n",
        "    prompt = f\"\"\"\n",
        "    User Profile:\n",
        "    - Age: {user_data['Age']}\n",
        "    - Gender: {user_data['Gender']}\n",
        "    - Purchase History: {user_data['Purchase History']}\n",
        "    - Sentiment Score: {user_data['Sentiment Score']}\n",
        "\n",
        "    Generate a personalized recommendation message for this user.\n",
        "    \"\"\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[{\"role\": \"system\", \"content\": prompt}]\n",
        "    )\n",
        "    return response['choices'][0]['message']['content']\n",
        "\n",
        "print(generate_personalized_message(101))"
      ],
      "metadata": {
        "id": "gKUSJ9ObwLLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wtyqyXoZwL-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5: Real-Time Learning"
      ],
      "metadata": {
        "id": "__3_1VdcwPJO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FFnqmKANwQlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "#Using Multi-Armed Bandits to adjust recommendations dynamically.\n",
        "class MultiArmedBandit:\n",
        "    def __init__(self, n_products):\n",
        "        self.n_products = n_products\n",
        "        self.counts = np.zeros(n_products)\n",
        "        self.values = np.zeros(n_products)\n",
        "\n",
        "    def select_product(self):\n",
        "        return np.argmax(self.values)\n",
        "\n",
        "    def update(self, chosen_product, reward):\n",
        "        self.counts[chosen_product] += 1\n",
        "        self.values[chosen_product] += (reward - self.values[chosen_product]) / self.counts[chosen_product]\n",
        "\n",
        "# Simulate Real-Time Learning\n",
        "bandit = MultiArmedBandit(n_products=5)\n",
        "selected_product = bandit.select_product()\n",
        "bandit.update(selected_product, reward=1)  # Reward if the user clicks on the recommended product"
      ],
      "metadata": {
        "id": "YA3aPiitwQ-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LKet2Ec1wXMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6: Deployment Using FastAPI\n",
        "\n"
      ],
      "metadata": {
        "id": "RDF1ihe2wZXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI\n",
        "import uvicorn\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "@app.get(\"/recommend/{user_id}\")\n",
        "def get_recommendations(user_id: int):\n",
        "    recommendations = recommend(user_id)\n",
        "    message = generate_personalized_message(user_id)\n",
        "    return {\"recommendations\": recommendations, \"message\": message}\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
      ],
      "metadata": {
        "id": "0VneZs3SwaqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aixwMFG0wjUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7: Business Insights & Dashboard"
      ],
      "metadata": {
        "id": "jn4ACOETwjp-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "st.title(\"AI-Driven Hyper-Personalization Dashboard\")\n",
        "\n",
        "# Load Processed Data\n",
        "df = pd.read_csv(\"processed_data.csv\")\n",
        "\n",
        "# Sentiment Distribution\n",
        "st.subheader(\"Customer Sentiment Distribution\")\n",
        "fig, ax = plt.subplots()\n",
        "df['Sentiment Score'].hist(ax=ax, bins=20)\n",
        "st.pyplot(fig)\n",
        "\n",
        "# Recommendation Results\n",
        "user_id = st.number_input(\"Enter User ID:\", min_value=100, max_value=200)\n",
        "if st.button(\"Get Recommendations\"):\n",
        "    st.write(\"Top Recommendations:\", recommend(user_id))\n",
        "    st.write(\"AI-Personalized Message:\", generate_personalized_message(user_id))"
      ],
      "metadata": {
        "id": "BS-RYmp2wlru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-zGC8BGJwq8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TWPO4E_Twu9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final Deliverables\n",
        "\n",
        " AI-Driven Hyper-Personalization System\n",
        "\n",
        " Collaborative & Content-Based\n",
        "\n",
        " Filtering Models\n",
        "\n",
        " Generative AI for Personalized Messages\n",
        "\n",
        " Real-time Adaptive Learning with\n",
        "\n",
        " Bandits\n",
        "\n",
        " FastAPI Deployment & Streamlit\n",
        "\n",
        " Dashboard\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "This end-to-end solution ensures hyper-personalized recommendations that dynamically adapt to user behavior in real time!"
      ],
      "metadata": {
        "id": "cpwz3fN4wwwW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4j4F8oUYwx60"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}